import sys
import re
import urllib.parse
import numpy as np
import pandas as pd
import pyodbc
from sqlalchemy import create_engine
from sklearn.preprocessing import MinMaxScaler
from sklearn.tree import DecisionTreeClassifier


if sys.stdout.encoding.lower() != "utf-8":
    sys.stdout.reconfigure(encoding="utf-8")
if sys.stderr.encoding.lower() != "utf-8":
    sys.stderr.reconfigure(encoding="utf-8")


# ============================================================
# 0. –ù–∞–ª–∞—à—Ç—É–≤–∞–Ω–Ω—è
# ============================================================

TARGET_STUDENT_ID = 1  # ID —Å—Ç—É–¥–µ–Ω—Ç–∞, —è–∫–æ–≥–æ –∞–Ω–∞–ª—ñ–∑—É—î–º–æ

# –ü–µ—Ä—ñ–æ–¥ –∞–Ω–∞–ª—ñ–∑—É:
#   "all"           ‚Äì –∞–Ω–∞–ª—ñ–∑ –≤—Å—ñ—Ö –¥–æ—Å—Ç—É–ø–Ω–∏—Ö —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ñ–≤
#   "current_class" ‚Äì –ª–∏—à–µ –ø–µ—Ä—ñ–æ–¥ –ø–æ—Ç–æ—á–Ω–æ–≥–æ –∫–ª–∞—Å—É (–∑–∞ –¥–∞–Ω–∏–º–∏ student —Ç–∞ student_class_history)
ANALYSIS_SCOPE = "all"  # –∞–±–æ "current_class"

RAW_CONNECTION_STRING = (
    "DRIVER={ODBC Driver 17 for SQL Server};"
    "SERVER=DESKTOP-GF8REUK\\SQLEXPRESS;"
    "DATABASE=EduTestDB;"
    "Trusted_Connection=yes;"
    "Encrypt=no;"
    "TrustServerCertificate=yes;"
)

quoted_params = urllib.parse.quote_plus(RAW_CONNECTION_STRING)
engine = create_engine(f"mssql+pyodbc:///?odbc_connect={quoted_params}")

# subject_id ‚Üí –Ω–∞–ø—Ä—è–º–æ–∫ –Ω–∞–≤—á–∞–Ω–Ω—è
SUBJECT_DIRECTION_MAP = {
    1: "–ì—É–º–∞–Ω—ñ—Ç–∞—Ä–Ω—ñ", 2: "–ì—É–º–∞–Ω—ñ—Ç–∞—Ä–Ω—ñ", 3: "–ì—É–º–∞–Ω—ñ—Ç–∞—Ä–Ω—ñ", 4: "–ì—É–º–∞–Ω—ñ—Ç–∞—Ä–Ω—ñ",
    5: "–ì—É–º–∞–Ω—ñ—Ç–∞—Ä–Ω—ñ", 6: "–ì—É–º–∞–Ω—ñ—Ç–∞—Ä–Ω—ñ",

    7: "–ú–∞—Ç–µ–º–∞—Ç–∏—á–Ω—ñ", 8: "–ú–∞—Ç–µ–º–∞—Ç–∏—á–Ω—ñ", 9: "–ú–∞—Ç–µ–º–∞—Ç–∏—á–Ω—ñ",
    21: "–ú–∞—Ç–µ–º–∞—Ç–∏—á–Ω—ñ",

    10: "–ü—Ä–∏—Ä–æ–¥–Ω–∏—á—ñ", 11: "–ü—Ä–∏—Ä–æ–¥–Ω–∏—á—ñ", 12: "–ü—Ä–∏—Ä–æ–¥–Ω–∏—á—ñ", 13: "–ü—Ä–∏—Ä–æ–¥–Ω–∏—á—ñ",
    14: "–ü—Ä–∏—Ä–æ–¥–Ω–∏—á—ñ", 15: "–ü—Ä–∏—Ä–æ–¥–Ω–∏—á—ñ", 16: "–ü—Ä–∏—Ä–æ–¥–Ω–∏—á—ñ",

    17: "–°—É—Å–ø—ñ–ª—å–Ω—ñ", 18: "–°—É—Å–ø—ñ–ª—å–Ω—ñ", 19: "–°—É—Å–ø—ñ–ª—å–Ω—ñ", 20: "–°—É—Å–ø—ñ–ª—å–Ω—ñ",
    31: "–°—É—Å–ø—ñ–ª—å–Ω—ñ", 32: "–°—É—Å–ø—ñ–ª—å–Ω—ñ",

    22: "–Ü–Ω—Ç–µ–≥—Ä–æ–≤–∞–Ω—ñ",

    23: "–¢–µ—Ö–Ω–æ–ª–æ–≥—ñ—á–Ω—ñ", 24: "–¢–µ—Ö–Ω–æ–ª–æ–≥—ñ—á–Ω—ñ",

    25: "–¢–≤–æ—Ä—á—ñ", 26: "–¢–≤–æ—Ä—á—ñ", 27: "–¢–≤–æ—Ä—á—ñ",

    28: "–§—ñ–∑–∫—É–ª—å—Ç—É—Ä–∞", 29: "–§—ñ–∑–∫—É–ª—å—Ç—É—Ä–∞", 30: "–§—ñ–∑–∫—É–ª—å—Ç—É—Ä–∞",
}


def detect_direction(subject_id: int) -> str:
    return SUBJECT_DIRECTION_MAP.get(subject_id, "–Ü–Ω—à–µ")


# –ù–∞–ø—Ä—è–º–æ–∫ ‚Üí –º–æ–∂–ª–∏–≤—ñ –∫–∞—Ä º—î—Ä–Ω—ñ —Ç—Ä–∞—î–∫—Ç–æ—Ä—ñ—ó
CAREER_SUGGESTIONS = {
    "–ú–∞—Ç–µ–º–∞—Ç–∏—á–Ω—ñ": "—ñ–Ω–∂–µ–Ω–µ—Ä–Ω—ñ —Å–ø–µ—Ü—ñ–∞–ª—å–Ω–æ—Å—Ç—ñ, –ø—Ä–æ–≥—Ä–∞–º—É–≤–∞–Ω–Ω—è, –∞–Ω–∞–ª—ñ–∑ –¥–∞–Ω–∏—Ö, —Ñ—ñ–Ω–∞–Ω—Å–æ–≤–∞ –∞–Ω–∞–ª—ñ—Ç–∏–∫–∞",
    "–ü—Ä–∏—Ä–æ–¥–Ω–∏—á—ñ": "–º–µ–¥–∏—Ü–∏–Ω–∞, –±—ñ–æ–ª–æ–≥—ñ—è, –µ–∫–æ–ª–æ–≥—ñ—è, –ª–∞–±–æ—Ä–∞—Ç–æ—Ä–Ω—ñ —Ç–∞ –Ω–∞—É–∫–æ–≤—ñ –¥–æ—Å–ª—ñ–¥–∂–µ–Ω–Ω—è",
    "–ì—É–º–∞–Ω—ñ—Ç–∞—Ä–Ω—ñ": "–∂—É—Ä–Ω–∞–ª—ñ—Å—Ç–∏–∫–∞, —Ñ—ñ–ª–æ–ª–æ–≥—ñ—è, –ø—Ä–∞–≤–æ, –ø–µ—Ä–µ–∫–ª–∞–¥, –ø–µ–¥–∞–≥–æ–≥—ñ–∫–∞",
    "–°—É—Å–ø—ñ–ª—å–Ω—ñ": "–ø—Ä–∞–≤–æ, –ø–æ–ª—ñ—Ç–æ–ª–æ–≥—ñ—è, —Å–æ—Ü—ñ–æ–ª–æ–≥—ñ—è, –º–µ–Ω–µ–¥–∂–º–µ–Ω—Ç, –ø—É–±–ª—ñ—á–Ω–µ —É–ø—Ä–∞–≤–ª—ñ–Ω–Ω—è",
    "–¢–µ—Ö–Ω–æ–ª–æ–≥—ñ—á–Ω—ñ": "—ñ–Ω–∂–µ–Ω–µ—Ä—ñ—è, —Ä–æ–±–æ—Ç–æ—Ç–µ—Ö–Ω—ñ–∫–∞, —Ç–µ—Ö–Ω–æ–ª–æ–≥—ñ—ó –≤–∏—Ä–æ–±–Ω–∏—Ü—Ç–≤–∞",
    "–¢–≤–æ—Ä—á—ñ": "–¥–∏–∑–∞–π–Ω, –º–∏—Å—Ç–µ—Ü—Ç–≤–æ, –º—É–∑–∏–∫–∞, –∫—Ä–µ–∞—Ç–∏–≤–Ω—ñ —ñ–Ω–¥—É—Å—Ç—Ä—ñ—ó",
    "–§—ñ–∑–∫—É–ª—å—Ç—É—Ä–∞": "—Å–ø–æ—Ä—Ç, —Ñ—ñ–∑–∏—á–Ω–∞ —Ä–µ–∞–±—ñ–ª—ñ—Ç–∞—Ü—ñ—è, —Ç—Ä–µ–Ω–µ—Ä—Å—å–∫–∞ –¥—ñ—è–ª—å–Ω—ñ—Å—Ç—å",
    "–Ü–Ω—Ç–µ–≥—Ä–æ–≤–∞–Ω—ñ": "–º—ñ–∂–¥–∏—Å—Ü–∏–ø–ª—ñ–Ω–∞—Ä–Ω—ñ –Ω–∞–ø—Ä—è–º–∏, STEAM-–ø—Ä–æ—î–∫—Ç–∏, –æ—Å–≤—ñ—Ç–Ω—ñ —Ç–µ—Ö–Ω–æ–ª–æ–≥—ñ—ó",
    "–Ü–Ω—à–µ": "—ñ–Ω–¥–∏–≤—ñ–¥—É–∞–ª—å–Ω–æ –ø—ñ–¥—ñ–±—Ä–∞–Ω—ñ –º—ñ–∂–¥–∏—Å—Ü–∏–ø–ª—ñ–Ω–∞—Ä–Ω—ñ –æ—Å–≤—ñ—Ç–Ω—ñ —Ç—Ä–∞—î–∫—Ç–æ—Ä—ñ—ó",
}

# ============================================================
# –†—ñ–≤–Ω—ñ —É—Å–ø—ñ—à–Ω–æ—Å—Ç—ñ –∑–∞ 12-–±–∞–ª—å–Ω–æ—é —à–∫–∞–ª–æ—é
# ============================================================

def score_to_level(score: float) -> int:
    if score <= 3:
        return 0
    elif score <= 6:
        return 1
    elif score <= 9:
        return 2
    else:
        return 3


LEVEL_NAME_MAP = {
    0: "–ø–æ—á–∞—Ç–∫–æ–≤–∏–π (1‚Äì3 –±–∞–ª–∏)",
    1: "—Å–µ—Ä–µ–¥–Ω—ñ–π (4‚Äì6 –±–∞–ª—ñ–≤)",
    2: "–¥–æ—Å—Ç–∞—Ç–Ω—ñ–π (7‚Äì9 –±–∞–ª—ñ–≤)",
    3: "–≤–∏—Å–æ–∫–∏–π (10‚Äì12 –±–∞–ª—ñ–≤)",
}

LEVEL_SHORT_NAME = {
    0: "–ø–æ—á–∞—Ç–∫–æ–≤–∏–π",
    1: "—Å–µ—Ä–µ–¥–Ω—ñ–π",
    2: "–¥–æ—Å—Ç–∞—Ç–Ω—ñ–π",
    3: "–≤–∏—Å–æ–∫–∏–π",
}


def level_to_name(level: int) -> str:
    return LEVEL_NAME_MAP.get(level, "–Ω–µ–≤—ñ–¥–æ–º–∏–π —Ä—ñ–≤–µ–Ω—å")


def format_forecast_level(score: float) -> str:
    """
    –§–æ—Ä–º–∞—Ç –¥–ª—è –ø—Ä–æ–≥–Ω–æ–∑—É: "–¥–æ—Å—Ç–∞—Ç–Ω—ñ–π (8 –±–∞–ª—ñ–≤)"
    """
    lvl = score_to_level(score)
    short = LEVEL_SHORT_NAME.get(lvl, "–Ω–µ–≤—ñ–¥–æ–º–∏–π —Ä—ñ–≤–µ–Ω—å")
    return f"{short} ({round(score)} –±–∞–ª—ñ–≤)"


# ============================================================
# –í–∏—Ç—è–≥ —Ç–µ–º–∏ –∑ –Ω–∞–∑–≤–∏ —Ç–µ—Å—Ç—É
# ============================================================

def extract_topic_from_test_name(test_name: str) -> str:
    """
    –í–∏—Ç—è–≥—É—î —Ç–µ–º—É –∑ –Ω–∞–∑–≤–∏ —Ç–µ—Å—Ç—É:
    —à—É–∫–∞—î–º–æ –ø–µ—Ä—à–∏–π —Ñ—Ä–∞–≥–º–µ–Ω—Ç —É –±—É–¥—å-—è–∫–∏—Ö –ª–∞–ø–∫–∞—Ö (' " ¬´ ¬ª ‚Ä¶).
    –Ø–∫—â–æ –Ω—ñ—á–æ–≥–æ –Ω–µ –∑–Ω–∞–π—à–ª–∏ ‚Äì "–Ω–µ–≤–∏–∑–Ω–∞—á–µ–Ω–∞ —Ç–µ–º–∞".
    """
    if not isinstance(test_name, str):
        return "–Ω–µ–≤–∏–∑–Ω–∞—á–µ–Ω–∞ —Ç–µ–º–∞"

    pattern = r"[\"'¬´¬ª‚Äú‚Äù‚Äû‚Äü‚Äö‚Äò‚Äô`](.+?)[\"'¬´¬ª‚Äú‚Äù‚Äû‚Äü‚Äö‚Äò‚Äô`]"
    m = re.search(pattern, test_name)
    if m:
        return m.group(1).strip()
    return "–Ω–µ–≤–∏–∑–Ω–∞—á–µ–Ω–∞ —Ç–µ–º–∞"


# ============================================================
# 1. –ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è –¥–∞–Ω–∏—Ö –∑ –ë–î (—É—Å—ñ —É—á–Ω—ñ)
# ============================================================

def load_all_scores() -> pd.DataFrame:
    """
    –í–∏—Ç—è–≥—É—î–º–æ –í–°–Ü –ø—Ä–æ—Ö–æ–¥–∂–µ–Ω–Ω—è —Ç–µ—Å—Ç—ñ–≤ (—É—Å—ñ—Ö —Å—Ç—É–¥–µ–Ω—Ç—ñ–≤) –∑—ñ state = 1.
    (–ë–µ–∑ —É—Ä–∞—Ö—É–≤–∞–Ω–Ω—è –∫–ª–∞—Å—ñ–≤ ‚Äî –∫–ª–∞—Å/–ø–µ—Ä—ñ–æ–¥ –ø—ñ–¥—Ç—è–≥—É—î–º–æ –æ–∫—Ä–µ–º–æ —á–µ—Ä–µ–∑ student_class_history.)
    """
    query = """
    SELECT
        st.[student_id],
        s.[first_name],
        s.[last_name],
        s.[patronymic_name],
        st.[test_id],
        st.[score],
        st.[state],
        st.[date_time_taken],
        t.[name] AS test_name,
        subj.[id] AS subject_id,
        subj.[name] AS subject_name
    FROM [EduTestDB].[dbo].[student_test] AS st
        INNER JOIN [EduTestDB].[dbo].[student] AS s
            ON s.[id] = st.[student_id]
        INNER JOIN [EduTestDB].[dbo].[test] AS t
            ON t.[id] = st.[test_id]
        INNER JOIN [EduTestDB].[dbo].[subject] AS subj
            ON subj.[id] = t.[subject_id]
    WHERE
        st.[state] = 1;
    """
    df = pd.read_sql(query, engine)

    # –í–∏—Ç—è–≥—É—î–º–æ —Ç–µ–º—É –∑ –Ω–∞–∑–≤–∏ —Ç–µ—Å—Ç—É
    df["topic"] = df["test_name"].apply(extract_topic_from_test_name)

    # –ö–æ–¥—É—î–º–æ —Ç–µ–º—É —è–∫ –∫–∞—Ç–µ–≥–æ—Ä—ñ—é –¥–ª—è –º–æ–¥–µ–ª—ñ
    df["topic_id"], _ = pd.factorize(df["topic"])

    return df


# ============================================================
# 1.1. –ü–µ—Ä—ñ–æ–¥ –ø–æ—Ç–æ—á–Ω–æ–≥–æ –∫–ª–∞—Å—É (—á–µ—Ä–µ–∑ student + student_class_history)
# ============================================================

def get_current_class_period(student_id: int):
    """
    –í–∏–∑–Ω–∞—á–∞—î –ø–µ—Ä—ñ–æ–¥ –ø–æ—Ç–æ—á–Ω–æ–≥–æ –∫–ª–∞—Å—É —Å—Ç—É–¥–µ–Ω—Ç–∞:
      1) —á–∏—Ç–∞—î–º–æ current_class_id –∑ —Ç–∞–±–ª–∏—Ü—ñ student;
      2) —à—É–∫–∞—î–º–æ –æ—Å—Ç–∞–Ω–Ω—ñ–π –∑–∞–ø–∏—Å —É student_class_history –¥–ª—è —Ü—å–æ–≥–æ class_id;
      3) –ø–æ–≤–µ—Ä—Ç–∞—î–º–æ (class_id, date_from, date_to).
    –Ø–∫—â–æ date_to = NULL, –≤–≤–∞–∂–∞—î–º–æ –≤–µ—Ä—Ö–Ω—é –º–µ–∂—É 9999-12-31.
    –Ø–∫—â–æ —â–æ—Å—å –Ω–µ –∑–Ω–∞–π—à–ª–∏ ‚Äî –ø–æ–≤–µ—Ä—Ç–∞—î–º–æ (None, None, None).
    """

    # 1) –ü–æ—Ç–æ—á–Ω–∏–π class_id –∑ –ø—Ä–æ—Ñ—ñ–ª—é
    q_profile = f"""
        SELECT [class_id]
        FROM [EduTestDB].[dbo].[student]
        WHERE [id] = {student_id}
    """
    df_profile = pd.read_sql(q_profile, engine)

    if df_profile.empty or pd.isna(df_profile.iloc[0]["class_id"]):
        print(f"DEBUG: student_id={student_id}: –Ω–µ –∑–Ω–∞–π–¥–µ–Ω–æ current class —É —Ç–∞–±–ª–∏—Ü—ñ student")
        return None, None, None

    current_class_id = int(df_profile.iloc[0]["class_id"])
    print(f"DEBUG: student_id={student_id}: current_class_id={current_class_id}")

    # 2) –ü–µ—Ä—ñ–æ–¥ —É —Ü—å–æ–º—É –∫–ª–∞—Å—ñ –∑ —ñ—Å—Ç–æ—Ä—ñ—ó
    q_period = f"""
        SELECT TOP 1 [date_from], [date_to]
        FROM [EduTestDB].[dbo].[student_class_history]
        WHERE [student_id] = {student_id} AND [class_id] = {current_class_id}
        ORDER BY [date_from] DESC;
    """
    df_period = pd.read_sql(q_period, engine)

    if df_period.empty:
        print(f"DEBUG: student_id={student_id}, class_id={current_class_id}: –∑–∞–ø–∏—Å—ñ–≤ —É student_class_history –Ω–µ–º–∞—î")
        return current_class_id, None, None

    date_from = df_period.iloc[0]["date_from"]
    date_to = df_period.iloc[0]["date_to"]

    if pd.isna(date_to):
        date_to = pd.to_datetime("9999-12-31")

    print(f"DEBUG: student_id={student_id}, class_id={current_class_id}: "
          f"period {date_from} .. {date_to}")

    return current_class_id, date_from, date_to


def filter_student_scope(df_student: pd.DataFrame) -> pd.DataFrame:
    df = df_student.copy()

    if ANALYSIS_SCOPE == "all":
        return df

    if ANALYSIS_SCOPE == "current_class":
        class_id, date_from, date_to = get_current_class_period(TARGET_STUDENT_ID)

        if class_id is None or date_from is None:
            return df

        mask = (
            df["date_time_taken"] >= pd.to_datetime(date_from)
        ) & (
            df["date_time_taken"] <= pd.to_datetime(date_to)
        )

        df_filtered = df[mask]
        return df_filtered

    return df


# ============================================================
# 2. –ù–∞–≤—á–∞–Ω–Ω—è –≥–ª–æ–±–∞–ª—å–Ω–æ—ó ML-–º–æ–¥–µ–ª—ñ
# ============================================================

def train_global_model(df_all: pd.DataFrame):
    df = df_all.copy()
    df["level"] = df["score"].apply(score_to_level)

    X = df[["score", "subject_id", "topic_id"]]
    y = df["level"]

    scaler = MinMaxScaler()
    X_scaled = scaler.fit_transform(X)

    model = DecisionTreeClassifier(
        criterion="gini",
        max_depth=6,
        random_state=42
    )
    model.fit(X_scaled, y)

    return model, scaler


def apply_model_to_student(df_student: pd.DataFrame, model, scaler) -> pd.DataFrame:
    df = df_student.copy()
    X = df[["score", "subject_id", "topic_id"]]
    X_scaled = scaler.transform(X)
    df["predicted_level"] = model.predict(X_scaled)
    return df


# ============================================================
# 3. –¢—Ä–µ–Ω–¥–æ–≤–µ –ø—Ä–æ–≥–Ω–æ–∑—É–≤–∞–Ω–Ω—è –ø–æ –æ—Å—Ç–∞–Ω–Ω—ñ—Ö –æ—Ü—ñ–Ω–∫–∞—Ö (–ø–æ –Ω–∞–ø—Ä—è–º–∫—É)
# ============================================================

def forecast_direction_score(df_dir: pd.DataFrame) -> float:
    """
    –ü—Ä–æ–≥–Ω–æ–∑–æ–≤–∞–Ω–∞ –û–¶–Ü–ù–ö–ê –¥–ª—è –ù–ê–ü–†–Ø–ú–ö–£ –∑ —É—Ä–∞—Ö—É–≤–∞–Ω–Ω—è–º –æ—Å—Ç–∞–Ω–Ω—ñ—Ö –æ—Ü—ñ–Ω–æ–∫.
    - –±–∞–∑–æ–≤–æ: –µ–∫—Å–ø–æ–Ω–µ–Ω—Ü—ñ–π–Ω–æ –∑–≤–∞–∂–µ–Ω–µ —Å–µ—Ä–µ–¥–Ω—î –ø–æ –±–∞–ª–∞—Ö (–æ—Å—Ç–∞–Ω–Ω—ñ –≤–∞–∂–∞—Ç—å –±—ñ–ª—å—à–µ);
    - —è–∫—â–æ –æ—Å—Ç–∞–Ω–Ω—ñ –æ—Ü—ñ–Ω–∫–∏ –ø–æ–º—ñ—Ç–Ω–æ –Ω–∏–∂—á—ñ/–≤–∏—â—ñ –∑–∞ –ø–æ–ø–µ—Ä–µ–¥–Ω—ñ ‚Äî –∫–æ—Ä–∏–≥—É—î–º–æ –Ω–∞ ¬±0.5.
    """
    df_dir = df_dir.sort_values("date_time_taken")
    scores = df_dir["score"].to_numpy(dtype=float)
    n = len(df_dir)

    if n == 0:
        return 0.0
    if n <= 2:
        return float(np.mean(scores))

    alpha = 0.6
    weights = np.array([alpha ** (n - 1 - i) for i in range(n)], dtype=float)
    base_score = float(np.sum(scores * weights) / np.sum(weights))

    if n >= 4:
        tail = min(4, n // 2)
        prev_scores = scores[:-tail]
        last_scores = scores[-tail:]

        if len(prev_scores) >= 3:
            prev_mean = float(np.mean(prev_scores))
            last_mean = float(np.mean(last_scores))

            if last_mean <= prev_mean - 1.0:
                base_score -= 0.5
            elif last_mean >= prev_mean + 1.0:
                base_score += 0.5

    base_score = max(1.0, min(12.0, base_score))
    return base_score


# ============================================================
# 3.1. –ü–æ—à—É–∫ –ø—Ä–µ–¥–º–µ—Ç—ñ–≤ —ñ–∑ —è–≤–Ω–æ –ø–æ–≥—ñ—Ä—à–µ–Ω–æ—é –¥–∏–Ω–∞–º—ñ–∫–æ—é
# ============================================================

def find_worsening_subjects(df: pd.DataFrame) -> list[str]:
    worsening: list[str] = []

    for subject, part in df.groupby("subject_name"):
        part = part.sort_values("date_time_taken")
        scores = part["score"].to_numpy(dtype=float)
        n = len(scores)

        if n < 5:
            continue

        tail = min(4, n // 2)
        prev_scores = scores[:-tail]
        last_scores = scores[-tail:]

        if len(prev_scores) < 3:
            continue

        prev_mean = float(np.mean(prev_scores))
        last_mean = float(np.mean(last_scores))

        if last_mean <= prev_mean - 0.5:
            worsening.append(subject)

    return sorted(set(worsening))


# ============================================================
# 4. –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü—ñ—ó –ø–æ –Ω–∞–ø—Ä—è–º–∫–∞—Ö —ñ —Ç–µ–º–∞—Ö
# ============================================================

def generate_direction_and_topic_recommendations(df_student_pred: pd.DataFrame):
    """
    –§–æ—Ä–º—É—î —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –ø–æ –Ω–∞–ø—Ä—è–º–∫–∞—Ö —ñ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü—ñ—ó.
    –¢–µ–ø–µ—Ä –¥–æ–¥–∞–Ω–æ:
      üÜï –ù–∞–π—Å–ª–∞–±—à—ñ —Ç–µ–º–∏ –ø–æ –í–°–Ü–• –ø—Ä–µ–¥–º–µ—Ç–∞—Ö.
      üÜï –Ü–≥–Ω–æ—Ä—É–≤–∞–Ω–Ω—è –ø—Ä–µ–¥–º–µ—Ç—ñ–≤, —è–∫—â–æ –Ω–∞–π—Å–ª–∞–±—à–∞ —Ç–µ–º–∞ –º–∞—î –≤–∏—Å–æ–∫–∏–π —Ä—ñ–≤–µ–Ω—å (10‚Äì12).
    """
    df = df_student_pred.copy()
    df["direction"] = df["subject_id"].apply(detect_direction)

    # ============================================================
    # 1. –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ —Ç–µ–º–∞—Ö
    # ============================================================
    topic_stats = (
        df.groupby(["direction", "subject_name", "topic"])
          .agg(avg_score=("score", "mean"), tests_count=("score", "count"))
          .reset_index()
    )
    topic_stats["avg_score"] = topic_stats["avg_score"].round(2)

    # ============================================================
    # 2. –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ –Ω–∞–ø—Ä—è–º–∫–∞—Ö
    # ============================================================
    dir_stats = (
        df.groupby("direction")
          .agg(
              avg_score=("score", "mean"),
              avg_level=("predicted_level", "mean"),
              tests_count=("score", "count")
          )
          .reset_index()
    )
    dir_stats["avg_score"] = dir_stats["avg_score"].round(2)
    dir_stats["avg_level"] = dir_stats["avg_level"].round(2)

    # –î–ª—è –∑—Ä—É—á–Ω–æ—Å—Ç—ñ —Å–ø–∏—Å–æ–∫ –ø—Ä–µ–¥–º–µ—Ç—ñ–≤ —É –∫–æ–∂–Ω–æ–º—É –Ω–∞–ø—Ä—è–º–∫—É
    subjects_per_direction = (
        df.groupby("direction")["subject_name"]
          .apply(lambda s: sorted(set(s)))
          .to_dict()
    )

    # ============================================================
    # 3. –§–æ—Ä–º—É—î–º–æ –ø—Ä–æ–≥–Ω–æ–∑ –¥–ª—è –∫–æ–∂–Ω–æ–≥–æ –Ω–∞–ø—Ä—è–º–∫—É
    # ============================================================
    forecast_info = []

    for _, row in dir_stats.iterrows():
        direction = row["direction"]
        avg_score = float(row["avg_score"])
        avg_level_num = float(row["avg_level"])
        tests_count = int(row["tests_count"])

        hist_level_int = int(round(avg_level_num))
        hist_level_text = level_to_name(hist_level_int)

        df_dir = df[df["direction"] == direction]
        forecast_score = forecast_direction_score(df_dir)
        forecast_level_int = score_to_level(forecast_score)
        forecast_level_display = format_forecast_level(forecast_score)

        forecast_info.append({
            "direction": direction,
            "avg_score": avg_score,
            "hist_level": hist_level_text,
            "hist_level_num": hist_level_int,
            "forecast_score": round(forecast_score, 2),
            "forecast_level": level_to_name(forecast_level_int),
            "forecast_level_num": forecast_level_int,
            "forecast_level_display": forecast_level_display,
            "tests_count": tests_count,
        })

    forecast_df = pd.DataFrame(forecast_info)

    # ============================================================
    # 4. –ù–∞–π—Å–∏–ª—å–Ω—ñ—à–∏–π –Ω–∞–ø—Ä—è–º–æ–∫
    # ============================================================
    if not forecast_df.empty:
        primary_row = (
            forecast_df.sort_values(
                by=["forecast_level_num", "forecast_score", "tests_count"],
                ascending=[False, False, False]
            ).iloc[0]
        )

        primary_direction = primary_row["direction"]
        primary_forecast_level_display = primary_row["forecast_level_display"]
        primary_avg_score = primary_row["avg_score"]
        primary_tests = int(primary_row["tests_count"])

        primary_subjects = subjects_per_direction.get(primary_direction, [])
        primary_subjects_str = ", ".join(primary_subjects) if primary_subjects else "‚Äî"

        primary_careers = CAREER_SUGGESTIONS.get(
            primary_direction, CAREER_SUGGESTIONS["–Ü–Ω—à–µ"]
        )
    else:
        primary_direction = None

    # ============================================================
    # 5. –°–ª–∞–±–∫—ñ –Ω–∞–ø—Ä—è–º–∫–∏ (—Å—Ç–∞—Ä–∞ –ª–æ–≥—ñ–∫–∞)
    # ============================================================
    weak_recommendation_text = None
    weak_topics_struct = []

    if not forecast_df.empty and len(forecast_df) > 1:
        min_level = forecast_df["forecast_level_num"].min()
        level_filtered = forecast_df[forecast_df["forecast_level_num"] == min_level]

        min_avg = level_filtered["avg_score"].min()
        weak_dirs_df = level_filtered[level_filtered["avg_score"] <= min_avg + 0.5]

        weak_blocks = []

        for _, wrow in weak_dirs_df.iterrows():
            wd = wrow["direction"]
            wd_avg_score = wrow["avg_score"]
            wd_tests = int(wrow["tests_count"])

            ts_dir = topic_stats[topic_stats["direction"] == wd]
            if ts_dir.empty:
                continue

            min_topic_avg = ts_dir["avg_score"].min()
            weakest_rows = ts_dir[ts_dir["avg_score"] <= min_topic_avg + 0.5]

            topic_descs = []
            for _, trow in weakest_rows.iterrows():
                subject = trow["subject_name"]
                topic = trow["topic"]
                t_avg = trow["avg_score"]

                weak_topics_struct.append({
                    "direction": wd,
                    "subject": subject,
                    "topic": topic,
                    "score": float(t_avg),
                })

                topic_descs.append(
                    f"{subject}, —Ç–µ–º–∞ ¬´{topic}¬ª (—Å–µ—Ä–µ–¥–Ω—ñ–π –±–∞–ª {t_avg})"
                )

            topics_str = "; ".join(topic_descs) if topic_descs else "‚Äî"

            weak_blocks.append(
                f"‚Ä¢ –Ω–∞–ø—Ä—è–º–æ–∫ ¬´{wd}¬ª (—Å–µ—Ä–µ–¥–Ω—ñ–π –±–∞–ª {wd_avg_score}, —Ç–µ—Å—Ç—ñ–≤ {wd_tests}); "
                f"–Ω–∞–π–±—ñ–ª—å—à–µ –≤—ñ–¥—Å—Ç–∞—é—Ç—å: {topics_str}"
            )

        if weak_blocks:
            weak_recommendation_text = (
                "–î–ª—è –∑–±–∞–ª–∞–Ω—Å–æ–≤–∞–Ω–æ–≥–æ —Ä–æ–∑–≤–∏—Ç–∫—É –≤–∞—Ä—Ç–æ –ø–æ—Å–∏–ª–∏—Ç–∏ –ø—ñ–¥—Ç—Ä–∏–º–∫—É "
                "–≤ —Ç–∞–∫–∏—Ö –Ω–∞–ø—Ä—è–º–∞—Ö —Ç–∞ —Ç–µ–º–∞—Ö:\n" + "\n".join(weak_blocks)
            )

    # ============================================================
    # 6. üÜï –ù–∞–π—Å–ª–∞–±—à—ñ —Ç–µ–º–∏ –ø–æ –í–°–Ü–• –ü–†–ï–î–ú–ï–¢–ê–• (–Ω–æ–≤–∞ –ª–æ–≥—ñ–∫–∞)
    # ============================================================
    weak_topics_all_subjects = []

    for subject, part in df.groupby("subject_name"):
        topic_means = (
            part.groupby("topic")["score"]
                .mean()
                .reset_index()
        )
        topic_means["score"] = topic_means["score"].round(2)

        min_score = topic_means["score"].min()
        worst_topics = topic_means[topic_means["score"] == min_score]

        if score_to_level(min_score) == 3:
            continue

        for _, trow in worst_topics.iterrows():
            weak_topics_all_subjects.append({
                "direction": detect_direction(
                    df[df["topic"] == trow["topic"]]["subject_id"].iloc[0]
                ),
                "subject": subject,
                "topic": trow["topic"],
                "score": float(trow["score"]),
            })

    weak_topics_struct.extend(weak_topics_all_subjects)

    # ============================================================
    # 7. –ü–æ–≥—ñ—Ä—à–µ–Ω–Ω—è —É –ø—Ä–µ–¥–º–µ—Ç–∞—Ö (—Å—Ç–∞—Ä–∞ –ª–æ–≥—ñ–∫–∞)
    # ============================================================
    worsening_subjects = find_worsening_subjects(df)
    worsening_text = None

    if worsening_subjects:
        subj_str = ", ".join(worsening_subjects)
        worsening_text = (
            f"–û–∫—Ä–µ–º–æ —Å–ª—ñ–¥ –∑–≤–µ—Ä–Ω—É—Ç–∏ —É–≤–∞–≥—É –Ω–∞ –ø—Ä–µ–¥–º–µ—Ç(–∏): {subj_str}, "
            f"–¥–µ –≤ –¥–∏–Ω–∞–º—ñ—Ü—ñ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ñ–≤ –ø—Ä–æ—Å—Ç–µ–∂—É—î—Ç—å—Å—è –∑–Ω–∏–∂–µ–Ω–Ω—è –æ—Ü—ñ–Ω–æ–∫."
        )

    # ============================================================
    # 8. –§–æ—Ä–º—É—î–º–æ —Ç–µ–∫—Å—Ç —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü—ñ–π
    # ============================================================
    recommendations = []

    if primary_direction is not None:
        recommendations.append(
            f"–û—Å–Ω–æ–≤–Ω–∏–π –æ—Å–≤—ñ—Ç–Ω—ñ–π –ø—Ä–æ—Ñ—ñ–ª—å: –Ω–∞–π—Å–∏–ª—å–Ω—ñ—à–∏–π –Ω–∞–ø—Ä—è–º–æ–∫ ‚Äî ¬´{primary_direction}¬ª "
            f"(—Å–µ—Ä–µ–¥–Ω—ñ–π –±–∞–ª {primary_avg_score}, –ø—Ä–æ–≥–Ω–æ–∑–æ–≤–∞–Ω–∏–π —Ä—ñ–≤–µ–Ω—å: {primary_forecast_level_display})."
        )
        recommendations.append(
            f"–ö–∞—Ä º—î—Ä–Ω—ñ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü—ñ—ó: {CAREER_SUGGESTIONS.get(primary_direction)}."
        )

    if weak_recommendation_text:
        recommendations.append(weak_recommendation_text)

    if worsening_text:
        recommendations.append(worsening_text)

    return forecast_df, recommendations, weak_topics_struct


# ============================================================
# 6. –ó–±–µ—Ä–µ–∂–µ–Ω–Ω—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ñ–≤ –∞–Ω–∞–ª—ñ–∑—É –≤ –ë–î
# ============================================================

def upsert_student_analysis(student_id, scope, class_id,
                            main_profile_text, career_text,
                            weak_directions_text, worsening_subjects_text):
    conn = pyodbc.connect(RAW_CONNECTION_STRING)
    cursor = conn.cursor()

    if scope == "all":
        cursor.execute("""
            SELECT id FROM dbo.student_analysis
            WHERE student_id = ? AND scope = N'all'
        """, (student_id,))
    else:
        cursor.execute("""
            SELECT id FROM dbo.student_analysis
            WHERE student_id = ? AND scope = N'current_class' AND class_id = ?
        """, (student_id, class_id))

    row = cursor.fetchone()

    if row:
        analysis_id = row.id
        cursor.execute("""
            UPDATE dbo.student_analysis
            SET 
                class_id = ?, 
                generated_at = SYSDATETIME(),
                main_profile_text = ?,
                career_text = ?,
                weak_directions_text = ?,
                worsening_subjects_text = ?
            WHERE id = ?
        """, (
            class_id,
            main_profile_text,
            career_text,
            weak_directions_text,
            worsening_subjects_text,
            analysis_id
        ))

        conn.commit()
        cursor.close()
        conn.close()
        return analysis_id

    cursor.execute("""
        INSERT INTO dbo.student_analysis(
            student_id, scope, class_id,
            main_profile_text, career_text,
            weak_directions_text, worsening_subjects_text
        ) OUTPUT INSERTED.id
        VALUES (?, ?, ?, ?, ?, ?, ?)
    """, (
        student_id, scope, class_id,
        main_profile_text, career_text,
        weak_directions_text, worsening_subjects_text
    ))

    analysis_id = cursor.fetchone()[0]
    conn.commit()
    cursor.close()
    conn.close()
    return analysis_id


def replace_analysis_directions(analysis_id, forecast_df: pd.DataFrame):
    """–ü–µ—Ä–µ–∑–∞–ø–∏—Å—É—î —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –Ω–∞–ø—Ä—è–º–∫—ñ–≤ (direction rows)."""
    conn = pyodbc.connect(RAW_CONNECTION_STRING)
    cursor = conn.cursor()

    # –í–∏–¥–∞–ª—è—î–º–æ —Å—Ç–∞—Ä—ñ –∑–∞–ø–∏—Å–∏
    cursor.execute("""
        DELETE FROM dbo.student_analysis_direction
        WHERE analysis_id = ?
    """, (analysis_id,))

    # –î–æ–¥–∞—î–º–æ –Ω–æ–≤—ñ
    for _, row in forecast_df.iterrows():
        cursor.execute("""
            INSERT INTO dbo.student_analysis_direction(
                analysis_id, direction_name,
                avg_score, hist_level,
                forecast_score, forecast_level,
                tests_count
            )
            VALUES (?, ?, ?, ?, ?, ?, ?)
        """, (
            analysis_id,
            row["direction"],
            float(row["avg_score"]),
            int(row["hist_level_num"]),
            float(row["forecast_score"]),
            int(row["forecast_level_num"]),
            int(row["tests_count"])
        ))

    conn.commit()
    cursor.close()
    conn.close()


def replace_analysis_weak_topics(analysis_id, weak_topics: list[dict]):
    """
    weak_topics ‚Äî —Å–ø–∏—Å–æ–∫ dict:
    [
        {
            "direction": "...",
            "subject": "...",
            "topic": "...",
            "score": 6.0
        },
        ...
    ]
    """
    conn = pyodbc.connect(RAW_CONNECTION_STRING)
    cursor = conn.cursor()

    # –≤–∏–¥–∞–ª—è—î–º–æ —Å—Ç–∞—Ä—ñ –∑–∞–ø–∏—Å–∏
    cursor.execute("""
        DELETE FROM dbo.student_analysis_weak_topics
        WHERE analysis_id = ?
    """, (analysis_id,))

    # –≤—Å—Ç–∞–≤–ª—è—î–º–æ –Ω–æ–≤—ñ
    for w in weak_topics:
        cursor.execute("""
            INSERT INTO dbo.student_analysis_weak_topics(
                analysis_id,
                direction_name,
                subject_name,
                topic_name,
                topic_score
            )
            VALUES (?, ?, ?, ?, ?)
        """, (
            analysis_id,
            w["direction"],
            w["subject"],
            w["topic"],
            float(w["score"])
        ))

    conn.commit()
    cursor.close()
    conn.close()


# ============================================================
# 7. –ì–æ–ª–æ–≤–Ω–∞ —Ñ—É–Ω–∫—Ü—ñ—è
# ============================================================

def main():
    df_all = load_all_scores()

    df_student = df_all[df_all["student_id"] == TARGET_STUDENT_ID].copy()
    print(f"DEBUG: student_id={TARGET_STUDENT_ID}, –≤—Å—å–æ–≥–æ –∑–∞–ø–∏—Å—ñ–≤ –¥–æ —Ñ—ñ–ª—å—Ç—Ä–∞: {len(df_student)}")

    df_student = filter_student_scope(df_student)
    print(f"DEBUG: –ø—ñ—Å–ª—è filter_student_scope, –∑–∞–ø–∏—Å—ñ–≤: {len(df_student)}")

    if df_student.empty:
        print("–ü—ñ—Å–ª—è –∑–∞—Å—Ç–æ—Å—É–≤–∞–Ω–Ω—è —Ñ—ñ–ª—å—Ç—Ä–∞ –ø–µ—Ä—ñ–æ–¥—É –¥–ª—è —Ü—å–æ–≥–æ —Å—Ç—É–¥–µ–Ω—Ç–∞ –Ω–µ –∑–∞–ª–∏—à–∏–ª–æ—Å—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ñ–≤.")
        return

    if df_all.empty:
        print("–£ –±–∞–∑—ñ –Ω–µ–º–∞—î –∂–æ–¥–Ω–æ–≥–æ –∑–∞–≤–µ—Ä—à–µ–Ω–æ–≥–æ —Ç–µ—Å—Ç—É.")
        return

    # 1) –ù–∞–≤—á–∞—î–º–æ –≥–ª–æ–±–∞–ª—å–Ω—É –º–æ–¥–µ–ª—å –Ω–∞ –í–°–Ü–• —É—á–Ω—è—Ö
    model, scaler = train_global_model(df_all)

    # 2) –ë–µ—Ä–µ–º–æ –æ–¥–Ω–æ–≥–æ —Ü—ñ–ª—å–æ–≤–æ–≥–æ —É—á–Ω—è
    df_student = df_all[df_all["student_id"] == TARGET_STUDENT_ID].copy()

    if df_student.empty:
        print(f"–î–ª—è —Å—Ç—É–¥–µ–Ω—Ç–∞ ID={TARGET_STUDENT_ID} –Ω–µ–º–∞—î –∑–∞–≤–µ—Ä—à–µ–Ω–∏—Ö —Ç–µ—Å—Ç—ñ–≤ (state = 1).")
        return

    # 2.1) –§—ñ–ª—å—Ç—Ä—É—î–º–æ –∑–∞ –æ–±—Ä–∞–Ω–∏–º –ø–µ—Ä—ñ–æ–¥–æ–º –∞–Ω–∞–ª—ñ–∑—É
    df_student = filter_student_scope(df_student)

    if df_student.empty:
        print("–ü—ñ—Å–ª—è –∑–∞—Å—Ç–æ—Å—É–≤–∞–Ω–Ω—è —Ñ—ñ–ª—å—Ç—Ä–∞ –ø–µ—Ä—ñ–æ–¥—É –¥–ª—è —Ü—å–æ–≥–æ —Å—Ç—É–¥–µ–Ω—Ç–∞ –Ω–µ –∑–∞–ª–∏—à–∏–ª–æ—Å—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ñ–≤.")
        return

    full_name = f"{df_student['last_name'].iloc[0]} " \
                f"{df_student['first_name'].iloc[0]} " \
                f"{df_student['patronymic_name'].iloc[0]}"

    print(f"\n=== ML-–∞–Ω–∞–ª—ñ–∑ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ñ–≤ —Å—Ç—É–¥–µ–Ω—Ç–∞: {full_name} (ID={TARGET_STUDENT_ID}) ===")
    print(f"–†–µ–∂–∏–º –∞–Ω–∞–ª—ñ–∑—É: {ANALYSIS_SCOPE}\n")

    # 3) –ó–∞—Å—Ç–æ—Å–æ–≤—É—î–º–æ –º–æ–¥–µ–ª—å –¥–æ —Ü—å–æ–≥–æ —É—á–Ω—è
    df_student_pred = apply_model_to_student(df_student, model, scaler)

    # 4) –ê–≥—Ä–µ–≥–∞—Ü—ñ—è –ø–æ –Ω–∞–ø—Ä—è–º–∫–∞—Ö + —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü—ñ—ó + —Å–ª–∞–±–∫—ñ —Ç–µ–º–∏ (—Å—Ç—Ä—É–∫—Ç—É—Ä–æ–≤–∞–Ω–æ)
    forecast_df, recs, weak_topics_struct = generate_direction_and_topic_recommendations(df_student_pred)

    print(">>> –ó–≤–µ–¥–µ–Ω–∞ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –∑–∞ –Ω–∞–ø—Ä—è–º–∫–∞–º–∏ (—ñ—Å—Ç–æ—Ä—ñ—è vs –ø—Ä–æ–≥–Ω–æ–∑):")
    for _, row in forecast_df.iterrows():
        print(
            f"- {row['direction']}: —Å–µ—Ä–µ–¥–Ω—ñ–π –±–∞–ª {row['avg_score']}, "
            f"—Ç–µ—Å—Ç—ñ–≤ {int(row['tests_count'])}, "
            f"—ñ—Å—Ç–æ—Ä–∏—á–Ω–∏–π —Ä—ñ–≤–µ–Ω—å: {row['hist_level']}, "
            f"–ø—Ä–æ–≥–Ω–æ–∑–æ–≤–∞–Ω–∏–π —Ä—ñ–≤–µ–Ω—å: {row['forecast_level_display']}"
        )

    print("\n>>> –ü–µ—Ä—Å–æ–Ω–∞–ª—ñ–∑–æ–≤–∞–Ω—ñ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü—ñ—ó –∑–∞ –Ω–∞–ø—Ä—è–º–∫–∞–º–∏, —Ç–µ–º–∞–º–∏ —Ç–∞ –º–æ–∂–ª–∏–≤–∏–º–∏ –∫–∞—Ä'—î—Ä–Ω–∏–º–∏ —Ç—Ä–∞—î–∫—Ç–æ—Ä—ñ—è–º–∏:")
    for r in recs:
        print("-", r)

    # ====================================================
    # –ó–ë–ï–†–ï–ñ–ï–ù–ù–Ø –ê–ù–ê–õ–Ü–ó–£ –í –ë–î
    # ====================================================

    # 1) —Ñ–æ—Ä–º—É—î–º–æ –æ—Å–Ω–æ–≤–Ω—ñ —Ç–µ–∫—Å—Ç–æ–≤—ñ –±–ª–æ–∫–∏
    main_profile_text = recs[0] if len(recs) > 0 else None
    career_text = recs[1] if len(recs) > 1 else None

    weak_directions_text = None
    worsening_subjects_text = None

    for r in recs[2:]:
        if "–Ω–∞–ø—Ä—è–º–∞—Ö —Ç–∞ —Ç–µ–º–∞—Ö" in r:
            weak_directions_text = r
        elif "–û–∫—Ä–µ–º–æ —Å–ª—ñ–¥ –∑–≤–µ—Ä–Ω—É—Ç–∏ —É–≤–∞–≥—É –Ω–∞ –ø—Ä–µ–¥–º–µ—Ç(–∏)" in r:
            worsening_subjects_text = r

    # 2) –≤–∏–∑–Ω–∞—á–∞—î–º–æ class_id –¥–ª—è scope='current_class'
    class_id = None
    if ANALYSIS_SCOPE == "current_class":
        class_id, _, _ = get_current_class_period(TARGET_STUDENT_ID)

    # 3) –≤—Å—Ç–∞–≤–ª—è—î–º–æ –∞–±–æ –æ–Ω–æ–≤–ª—é—î–º–æ –∑–∞–ø–∏—Å —É student_analysis
    analysis_id = upsert_student_analysis(
        TARGET_STUDENT_ID,
        ANALYSIS_SCOPE,
        class_id,
        main_profile_text,
        career_text,
        weak_directions_text,
        worsening_subjects_text
    )

    # 4) –≤—Å—Ç–∞–≤–ª—è—î–º–æ –¥–∞–Ω—ñ –ø–æ –Ω–∞–ø—Ä—è–º–∫–∞—Ö
    replace_analysis_directions(analysis_id, forecast_df)

    # 5) —Å–ª–∞–±–∫—ñ —Ç–µ–º–∏
    replace_analysis_weak_topics(analysis_id, weak_topics_struct)

    print(f"\n>>> –†–µ–∑—É–ª—å—Ç–∞—Ç–∏ –∑–±–µ—Ä–µ–∂–µ–Ω–æ –≤ –ë–î (analysis_id = {analysis_id})\n")

    df_student = df_all[df_all["student_id"] == TARGET_STUDENT_ID].copy()
    print(f"DEBUG: student_id={TARGET_STUDENT_ID}, –≤—Å—å–æ–≥–æ –∑–∞–ø–∏—Å—ñ–≤ –¥–æ —Ñ—ñ–ª—å—Ç—Ä–∞: {len(df_student)}")

    df_student = filter_student_scope(df_student)
    print(f"DEBUG: –ø—ñ—Å–ª—è filter_student_scope, –∑–∞–ø–∏—Å—ñ–≤: {len(df_student)}")

    if df_student.empty:
        print("–ü—ñ—Å–ª—è –∑–∞—Å—Ç–æ—Å—É–≤–∞–Ω–Ω—è —Ñ—ñ–ª—å—Ç—Ä–∞ –ø–µ—Ä—ñ–æ–¥—É –¥–ª—è —Ü—å–æ–≥–æ —Å—Ç—É–¥–µ–Ω—Ç–∞ –Ω–µ –∑–∞–ª–∏—à–∏–ª–æ—Å—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ñ–≤.")
        return


if __name__ == "__main__":
    if len(sys.argv) >= 2:
        try:
            TARGET_STUDENT_ID = int(sys.argv[1])
        except ValueError:
            print(f"–ù–µ–∫–æ—Ä–µ–∫—Ç–Ω–∏–π student_id: {sys.argv[1]}")

    if len(sys.argv) >= 3:
        ANALYSIS_SCOPE = sys.argv[2]

    main()
